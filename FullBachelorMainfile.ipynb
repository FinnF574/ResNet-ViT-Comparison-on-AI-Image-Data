{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514e31c8-ad55-446a-87cd-7dcabf0afd6d",
   "metadata": {},
   "source": [
    "# Bachelor Thesis Finn Franken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2845e4b-0393-49b3-bd49-a2c834948e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d11d3-d749-418b-801b-71de86d71eb9",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380ff3df-2dec-43a0-9ce2-ce1546e5ea7c",
   "metadata": {},
   "source": [
    "### Check the amount of data in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834a342f-e937-47ad-b79d-90d29b0a62fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fakecount = 0\n",
    "realcount = 0\n",
    "for i in os.listdir(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/FakeFaces\"):\n",
    "    fakecount+=1\n",
    "for i in os.listdir(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/RealFaces\"):\n",
    "    realcount+=1\n",
    "    \n",
    "print(\"Fakecount = \", fakecount)\n",
    "print(\"Realcount = \", realcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334fa17-d815-4298-aea2-c4ad8191370b",
   "metadata": {},
   "source": [
    "### Combining the two datasets into a single, labelled set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273ad74b-c5e5-4201-9118-4960a1e94581",
   "metadata": {},
   "source": [
    "real_ is added as a prefix to the real image names and ai_ is added to the ai image names. Images are then shuffled so the model can't learn from the order in which the data is fed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb9b07-612a-49fa-948b-e454c3d14ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/RealFaces\"):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        os.rename(\n",
    "            os.path.join(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/RealFaces\", filename),\n",
    "            os.path.join(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/AllFaces\", f'real_{filename}')\n",
    "        )\n",
    "\n",
    "for filename in os.listdir(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/FakeFaces\"):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        os.rename(\n",
    "            os.path.join(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/FakeFaces\", filename),\n",
    "            os.path.join(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/AllFaces\", f'ai_{filename}')\n",
    "        )\n",
    "\n",
    "#Gets a list of all images in the combined folder\n",
    "combined_images = [f for f in os.listdir(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/AllFaces\") if f.endswith('.jpg') or f.endswith('.png')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3282e4b-9e19-4ff4-bb34-f13d7192e2fe",
   "metadata": {},
   "source": [
    "### Splitting the data into Training (80%) and Testing (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6446b93e-6238-4d4c-a653-d67590263c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_images = len(combined_images)\n",
    "train_size = int(0.8 * total_images)\n",
    "test_size = total_images - train_size\n",
    "\n",
    "train_images = random.sample(combined_images, train_size)\n",
    "\n",
    "for image in combined_images:\n",
    "    if image in train_images:\n",
    "        shutil.move(os.path.join(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/AllFaces\", image), os.path.join(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/TrainFaces\", image))\n",
    "    else:\n",
    "        shutil.move(os.path.join(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/AllFaces\", image), os.path.join(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/TestFaces\", image))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558e967-95a5-4d01-8ae0-68dfb62b09c7",
   "metadata": {},
   "source": [
    "### Organizing the images into the correct input format for ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f4e11b-a722-4cf8-8c4e-916e20fe27b0",
   "metadata": {},
   "source": [
    "Test Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34594a06-bc49-4223-bf70-3a49b902014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/TestFaces\"):\n",
    "    if image.startswith('ai_'):\n",
    "        shutil.move(os.path.join(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/TestFaces\", image), os.path.join(\"C:/Users/bolly/1BachelorThesis/mainfolder/TestFaces/fake\", image))\n",
    "    elif image.startswith('real_'):\n",
    "        shutil.move(os.path.join(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/TestFaces\", image), os.path.join(\"C:/Users/bolly/1BachelorThesis/mainfolder/TestFaces/real\", image))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69344efe-6d58-498f-8b4b-03d48fee5fe3",
   "metadata": {},
   "source": [
    "Training Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d104a-4e66-4d10-bb93-7834ec7987cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/TrainFaces\"):\n",
    "    if image.startswith('ai_'):\n",
    "        shutil.move(os.path.join(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/TrainFaces\", image), os.path.join(\"C:/Users/bolly/1BachelorThesis/mainfolder/TrainFaces/fake\", image))\n",
    "    elif image.startswith('real_'):\n",
    "        shutil.move(os.path.join(\"C:/Users/bolly/1BachelorThesis/fullmainfolder/TrainFaces\", image), os.path.join(\"C:/Users/bolly/1BachelorThesis/mainfolder/TrainFaces/real\", image))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef58ae1-ada9-49a7-8c72-4dd5cde982a0",
   "metadata": {},
   "source": [
    "This following code simply serves to remove the .ipynb_checkpoints file that Jupyterlab automatically creates for autosave purposes. It caused issues when calling datasets.ImageFolder since ImageFolder saw it, but raised an error as it was not a png, jpg, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd8586-5ca4-4357-b929-c07e429bdc23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoints_dir = 'C:/Users/bolly/1BachelorThesis/fullmainfolder/TrainFaces/.ipynb_checkpoints'\n",
    "\n",
    "if os.path.exists(checkpoints_dir):\n",
    "    shutil.rmtree(checkpoints_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8ace65-253c-4133-bc07-db9a9b9f5ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoints_dir = 'C:/Users/bolly/1BachelorThesis/fullmainfolder/TestFaces/.ipynb_checkpoints'\n",
    "\n",
    "if os.path.exists(checkpoints_dir):\n",
    "    shutil.rmtree(checkpoints_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf6407-7522-49d1-8228-9223ac92914d",
   "metadata": {},
   "source": [
    "### Creating Datasets And Dataloaders for use in the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03c4a6-d102-4447-b92a-639c46d6da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"C:/Users/bolly/1BachelorThesis/fullmainfolder/TrainFaces\"\n",
    "test_data_dir = \"C:/Users/bolly/1BachelorThesis/fullmainfolder/TestFaces\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #Standard values for models trained on ImageNet\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_data_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_data_dir, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bf2394-843f-4493-9d37-cf0763c643eb",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d94b9fc-6e32-4717-983d-aa82739bdce9",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d57500-cb98-41bc-a53c-4e2ec4be731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True) #Loads pre-trained ResNet-50 model\n",
    "num_ftrs = model.fc.in_features #Gets the number of input features for the fully connected layer\n",
    "model.fc = nn.Linear(num_ftrs, 2) #Replaces the output layer for binary classification\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) #Stochastic Gradient Descent\n",
    "criterion = nn.CrossEntropyLoss() #Cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c2789b-c9b6-44ff-89ae-e61557182ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "train_model(model, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdd32ea-7dd6-4dfb-8e0b-e552dc97efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            y_true.extend(labels.numpy())\n",
    "            y_pred.extend(predicted.numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    \n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4fe26e-f3f1-4864-b15d-71ba79703852",
   "metadata": {},
   "source": [
    "## ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739e8cba-a1cf-4cfe-8b77-77ddcb5e6326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "model_name = \"google/vit-base-patch16-224-in21k\" #Loads the pre-trained ViT model trained on ImageNet21k\n",
    "model = ViTForImageClassification.from_pretrained(model_name) #Initializes the model\n",
    "image_processor = ViTImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5) #Adam optimizer\n",
    "criterion = nn.CrossEntropyLoss() #Cross-entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b1cb05-e356-4fa9-8cf3-0db29c3b8502",
   "metadata": {},
   "source": [
    "### Training ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97162b58-2019-44a5-9f17-4e04aaf6fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.logits.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "train(model, train_loader, optimizer, criterion, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cce4f1-af9f-4953-972d-1636caa11e30",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f822a9-4885-4781-9231-fb931100c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.logits.max(1)\n",
    "            true_labels.extend(labels.numpy())\n",
    "            predicted_labels.extend(predicted.numpy())\n",
    "\n",
    "    accuracy = (np.array(predicted_labels) == np.array(true_labels)).mean() * 100\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    \n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eca5f63-7236-4446-ae02-215001935209",
   "metadata": {},
   "source": [
    "## Noise Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597e840-ea7e-4d55-8f2d-342cb703eb37",
   "metadata": {},
   "source": [
    "This part will add a Gaussian Noise transform to the training dataloader. The original images will remain unaffected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a017d9-fc2f-4dfc-897b-b02cfca6dd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0, std=0.1):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        noise = torch.randn_like(tensor) * self.std + self.mean #Generates noise\n",
    "        noisy_tensor = tensor + noise #Adds noise\n",
    "        noisy_tensor = torch.clamp(noisy_tensor, 0, 1) #Ensures pixel values remain in the valid range\n",
    "        return noisy_tensor\n",
    "\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #Identical transformations to the ones used earlier\n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    base_transform,\n",
    "    AddGaussianNoise(mean=0, std=0.1),  #Transformations with noise for training data\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_data_dir, transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_data_dir, transform=base_transform)\n",
    "\n",
    "#Creates dataloaders with identical parameters to the ones sued before\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6490c70-779b-4c1f-8201-9bd0e4791443",
   "metadata": {},
   "source": [
    "## ResNet with Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f149632-0038-4dbc-acfb-c122f84703a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True) #Loads pre-trained ResNet-50 model\n",
    "num_ftrs = model.fc.in_features #Gets the number of input features for the fully connected layer\n",
    "model.fc = nn.Linear(num_ftrs, 2) #Replaces the output layer for binary classification\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) #Stochastic Gradient Descent\n",
    "criterion = nn.CrossEntropyLoss() #Cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c773660b-7da8-4f80-890d-3b28be6c9ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "train_model(model, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b3b1f-944c-4358-a2f3-1221eca2aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            y_true.extend(labels.numpy())\n",
    "            y_pred.extend(predicted.numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    \n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad08038a-8bc1-411b-ae61-7d33e1ad44f3",
   "metadata": {},
   "source": [
    "## ViT with Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78563a68-65f1-4515-bf0f-2d4556c7bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "model_name = \"google/vit-base-patch16-224-in21k\" #Loads the pre-trained ViT model trained on ImageNet21k\n",
    "model = ViTForImageClassification.from_pretrained(model_name) #Initializes the model\n",
    "image_processor = ViTImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5) #Adam optimizer\n",
    "criterion = nn.CrossEntropyLoss() #Cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a890cd-83c5-43cc-9f78-b2959b06ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.logits.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "train(model, train_loader, optimizer, criterion, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e70d7-3999-44d5-9a0d-ba2d827c47a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.logits.max(1)\n",
    "            true_labels.extend(labels.numpy())\n",
    "            predicted_labels.extend(predicted.numpy())\n",
    "\n",
    "    accuracy = (np.array(predicted_labels) == np.array(true_labels)).mean() * 100\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    \n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "evaluate(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
